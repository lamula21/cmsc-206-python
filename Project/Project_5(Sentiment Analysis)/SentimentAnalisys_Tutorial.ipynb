{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Sentiment Analysis in Python With TextBlob](https://stackabuse.com/sentiment-analysis-in-python-with-textblob/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithms of sentiment analysis mostly focus on defining opinions, attitudes, and even emoticons in a corpus of texts.\n",
    "\n",
    "It defines up to three basic polar emotions (positive, negative, neutral), the limit of more advanced models is broader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = https://stackabuse.s3.amazonaws.com/media/sentiment-analysis-in-python-with-textblob-1.jpg width=\"600px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob’s output for a polarity task is a float within the range `[-1.0, 1.0]` where `-1.0` is a negative polarity and `1.0` is positive. This score can also be equal to `0`, which stands for a neutral evaluation of a statement as it doesn’t contain any words from the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We first import `TextBlob` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing TextBlob\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Once imported, we'll load in a sentence for analysis and instantiate a `TextBlob` object, as well as assigning the `sentiment` property to our own `analysis`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.5, subjectivity=0.26666666666666666)\n"
     ]
    }
   ],
   "source": [
    "# Preparing an input sentence\n",
    "sentence = '''The platform provides universal access to the world's best education, partnering with top universities and organizations to offer courses online.'''\n",
    "\n",
    "# Creating a textblob object and assigning the sentiment property\n",
    "analysis = TextBlob(sentence).sentiment\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The `sentiment` property is a `namedtuple` of the form `Sentiment(polarity, subjectivity)`.\n",
    "\n",
    " Where the expected output of the analysis is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `Sentiment(polarity=0.5, subjectivity=0.26666666666666666)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Moreover, it’s also possible to go for polarity or subjectivity results separately by simply running the following*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Preparing an input sentence\n",
    "sentence = '''The platform provides universal access to the world's best education, partnering with top universities and organizations to offer courses online.'''\n",
    "\n",
    "analysisPol = TextBlob(sentence).polarity\n",
    "analysisSub = TextBlob(sentence).subjectivity\n",
    "\n",
    "print(analysisPol)\n",
    "print(analysisSub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "One of the great things about TextBlob is that it allows the user to choose an algorithm for implementation of the high-level NLP tasks:\n",
    "\n",
    " - `PatternAnalyzer` - a default classifier that is built on the pattern library\n",
    " - `NaiveBayesAnalyzer` - an NLTK model trained on a movie reviews corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the default settings, we'll simply specify a `NaiveBayes` analyzer in the code. Let’s run sentiment analysis on tweets directly from *Twitter*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "# For parsing tweets\n",
    "import tweepy \n",
    "\n",
    "# Importing the NaiveBayesAnalyzer classifier from NLTK\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " After that, we need to establish a connection with the Twitter API via API keys (that you can get through a `developer account`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading api keys and tokens\n",
    "api_key = 'zkHL8gUupR20SVVlmlruqrk2N'\n",
    "api_secret = 'sMYG0dAjk1ojegzeYIUX24iw983IWoIhXAYmfSLDxTwTtiAFJf'\n",
    "access_token = '1507476365209223177-tT7Ur8dc3zTqinEuFF3YwP9nTcbWqY'\n",
    "access_secret = 'z3cmW4PsR7SZtZG7harfHuBwFDYIss5No1XZbp9GJbr06'\n",
    "\n",
    "# Establishing the connection\n",
    "twitter = tweepy.OAuthHandler(api_key, api_secret)\n",
    "api = tweepy.API(twitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can perform the analysis of tweets on any topic. A searched word (e.g. lockdown) can be both one word or more. Moreover, this task can be time-consuming due to a tremendous amount of tweets. It's recommended to limit the output:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @taniadysan: Seguindo a China, a Austrália entra em \"lockdown\". Agora as clínicas estão sobrecarregadas devido a ataques cardíacos.\n",
      "ATAQ…\n",
      "RT @aqualimits: sorry to everyone in my life but i'm on purple lockdown until june and then i cannot be making any plans whatsoever until i…\n",
      "RT @hoonieloaf: on a LOCKDOWN https://t.co/uUSTvFaHXt\n",
      "Τι θα επιτρέψει τη χαλαρότητα του lockdown στη Σανγκάη; «Διορία» έως την Τετάρτη για «στοπ» στη μετάδοση του κορονο… https://t.co/fDBHnT43GS\n",
      "RT @pjmsyu: dia 10 de junho já eh feriado nacional pra mim não marquem compromissos comigo não me chamem não falem comigo não ousem me tira…\n"
     ]
    }
   ],
   "source": [
    "# This command will call back 5 tweets within a “lockdown” topic\n",
    "corpus_tweets = api.search_tweets(\"lockdown\", count=5) \n",
    "for tweet in corpus_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step in this example is switching the default model to the NLTK analyzer that returns its results as a `namedtuple` of the form: Sentiment`(classification, p_pos, p_neg)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n"
     ]
    }
   ],
   "source": [
    "# Applying the NaiveBayesAnalyzer\n",
    "blob_object = TextBlob(tweet.text, analyzer=NaiveBayesAnalyzer())\n",
    "\n",
    "# Running sentiment analysis\n",
    "analysis = blob_object.sentiment\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it's classified it as a `positive` sentiment, with the `p_pos` and `p_neg` values being `~0.5` each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# [Tutorial: Simple Text Classification with Python and TextBlob](https://stackabuse.com/sentiment-analysis-in-python-with-textblob/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: A Tweet Sentiment Analyzer (Simple classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first classifier will be a simple sentiment analyzer trained on a small dataset of fake tweets.\n",
    "\n",
    "To begin, we'll import the textblob.classifiers and create some training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "train = [\n",
    "    ('I love this sandwich.', 'pos'),\n",
    "    ('This is an amazing place!', 'pos'),\n",
    "    ('I feel very good about these beers.', 'pos'),\n",
    "    ('This is my best work.', 'pos'),\n",
    "    (\"What an awesome view\", 'pos'),\n",
    "    ('I do not like this restaurant', 'neg'),\n",
    "    ('I am tired of this stuff.', 'neg'),\n",
    "    (\"I can't deal with this\", 'neg'),\n",
    "    ('He is my sworn enemy!', 'neg'),\n",
    "    ('My boss is horrible.', 'neg')\n",
    "]\n",
    "test = [\n",
    "    ('The beer was good.', 'pos'),\n",
    "    ('I do not enjoy my job', 'neg'),\n",
    "    (\"I ain't feeling dandy today.\", 'neg'),\n",
    "    (\"I feel amazing!\", 'pos'),\n",
    "    ('Gary is a friend of mine.', 'pos'),\n",
    "    (\"I can't believe I'm doing this.\", 'neg')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new classifier by passing training data into the constructor for a `NaiveBayesClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now classify arbitrary text using the `NaiveBayesClassifier.classify(text)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.classify(\"Their burgers are amazing\")  # \"pos\"\n",
    "cl.classify(\"I don't like their pizza.\")  # \"neg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Another way to classify strings of text is to use TextBlob objects. You can pass classifiers into the constructor of a TextBlob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(\"The beer was amazing. \" \n",
    "                \"But the hangover was horrible. My boss was not happy.\",\n",
    "                classifier=cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then call the `classify()` method on the blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.classify()  # \"neg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "You can also take advantage of TextBlob's sentence tokenization and classify each sentence indvidually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The beer was amazing.\n",
      "pos\n",
      "But the hangover was horrible.\n",
      "neg\n",
      "My boss was not happy.\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob.sentences:\n",
    "    print(sentence)\n",
    "    print(sentence.classify())\n",
    "# \"pos\", \"neg\", \"neg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's check the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(test)\n",
    "# 0.83"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We can also find the most informative features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(this) = True              neg : pos    =      2.3 : 1.0\n",
      "          contains(this) = False             pos : neg    =      1.8 : 1.0\n",
      "          contains(This) = False             neg : pos    =      1.6 : 1.0\n",
      "            contains(an) = False             neg : pos    =      1.6 : 1.0\n",
      "             contains(I) = False             pos : neg    =      1.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This indicates that tweets containing the word \"my\" but not containing the word \"place\" tend to be negative.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Adding More Data from NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve our classifier by adding more training and test data. Here we'll add data from the movie review corpus which was downloaded with NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "reviews = [(list(movie_reviews.words(fileid)), category)\n",
    "              for category in movie_reviews.categories()\n",
    "              for fileid in movie_reviews.fileids(category)]\n",
    "new_train, new_test = reviews[0:100], reviews[101:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what one of these documents looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an', 'accident', '.', 'one', 'of', 'the', 'guys', 'dies', ',', 'but', 'his', 'girlfriend', 'continues', 'to', 'see', 'him', 'in', 'her', 'life', ',', 'and', 'has', 'nightmares', '.', 'what', \"'\", 's', 'the', 'deal', '?', 'watch', 'the', 'movie', 'and', '\"', 'sorta', '\"', 'find', 'out', '.', '.', '.', 'critique', ':', 'a', 'mind', '-', 'fuck', 'movie', 'for', 'the', 'teen', 'generation', 'that', 'touches', 'on', 'a', 'very', 'cool', 'idea', ',', 'but', 'presents', 'it', 'in', 'a', 'very', 'bad', 'package', '.', 'which', 'is', 'what', 'makes', 'this', 'review', 'an', 'even', 'harder', 'one', 'to', 'write', ',', 'since', 'i', 'generally', 'applaud', 'films', 'which', 'attempt', 'to', 'break', 'the', 'mold', ',', 'mess', 'with', 'your', 'head', 'and', 'such', '(', 'lost', 'highway', '&', 'memento', ')', ',', 'but', 'there', 'are', 'good', 'and', 'bad', 'ways', 'of', 'making', 'all', 'types', 'of', 'films', ',', 'and', 'these', 'folks', 'just', 'didn', \"'\", 't', 'snag', 'this', 'one', 'correctly', '.', 'they', 'seem', 'to', 'have', 'taken', 'this', 'pretty', 'neat', 'concept', ',', 'but', 'executed', 'it', 'terribly', '.', 'so', 'what', 'are', 'the', 'problems', 'with', 'the', 'movie', '?', 'well', ',', 'its', 'main', 'problem', 'is', 'that', 'it', \"'\", 's', 'simply', 'too', 'jumbled', '.', 'it', 'starts', 'off', '\"', 'normal', '\"', 'but', 'then', 'downshifts', 'into', 'this', '\"', 'fantasy', '\"', 'world', 'in', 'which', 'you', ',', 'as', 'an', 'audience', 'member', ',', 'have', 'no', 'idea', 'what', \"'\", 's', 'going', 'on', '.', 'there', 'are', 'dreams', ',', 'there', 'are', 'characters', 'coming', 'back', 'from', 'the', 'dead', ',', 'there', 'are', 'others', 'who', 'look', 'like', 'the', 'dead', ',', 'there', 'are', 'strange', 'apparitions', ',', 'there', 'are', 'disappearances', ',', 'there', 'are', 'a', 'looooot', 'of', 'chase', 'scenes', ',', 'there', 'are', 'tons', 'of', 'weird', 'things', 'that', 'happen', ',', 'and', 'most', 'of', 'it', 'is', 'simply', 'not', 'explained', '.', 'now', 'i', 'personally', 'don', \"'\", 't', 'mind', 'trying', 'to', 'unravel', 'a', 'film', 'every', 'now', 'and', 'then', ',', 'but', 'when', 'all', 'it', 'does', 'is', 'give', 'me', 'the', 'same', 'clue', 'over', 'and', 'over', 'again', ',', 'i', 'get', 'kind', 'of', 'fed', 'up', 'after', 'a', 'while', ',', 'which', 'is', 'this', 'film', \"'\", 's', 'biggest', 'problem', '.', 'it', \"'\", 's', 'obviously', 'got', 'this', 'big', 'secret', 'to', 'hide', ',', 'but', 'it', 'seems', 'to', 'want', 'to', 'hide', 'it', 'completely', 'until', 'its', 'final', 'five', 'minutes', '.', 'and', 'do', 'they', 'make', 'things', 'entertaining', ',', 'thrilling', 'or', 'even', 'engaging', ',', 'in', 'the', 'meantime', '?', 'not', 'really', '.', 'the', 'sad', 'part', 'is', 'that', 'the', 'arrow', 'and', 'i', 'both', 'dig', 'on', 'flicks', 'like', 'this', ',', 'so', 'we', 'actually', 'figured', 'most', 'of', 'it', 'out', 'by', 'the', 'half', '-', 'way', 'point', ',', 'so', 'all', 'of', 'the', 'strangeness', 'after', 'that', 'did', 'start', 'to', 'make', 'a', 'little', 'bit', 'of', 'sense', ',', 'but', 'it', 'still', 'didn', \"'\", 't', 'the', 'make', 'the', 'film', 'all', 'that', 'more', 'entertaining', '.', 'i', 'guess', 'the', 'bottom', 'line', 'with', 'movies', 'like', 'this', 'is', 'that', 'you', 'should', 'always', 'make', 'sure', 'that', 'the', 'audience', 'is', '\"', 'into', 'it', '\"', 'even', 'before', 'they', 'are', 'given', 'the', 'secret', 'password', 'to', 'enter', 'your', 'world', 'of', 'understanding', '.', 'i', 'mean', ',', 'showing', 'melissa', 'sagemiller', 'running', 'away', 'from', 'visions', 'for', 'about', '20', 'minutes', 'throughout', 'the', 'movie', 'is', 'just', 'plain', 'lazy', '!', '!', 'okay', ',', 'we', 'get', 'it', '.', '.', '.', 'there', 'are', 'people', 'chasing', 'her', 'and', 'we', 'don', \"'\", 't', 'know', 'who', 'they', 'are', '.', 'do', 'we', 'really', 'need', 'to', 'see', 'it', 'over', 'and', 'over', 'again', '?', 'how', 'about', 'giving', 'us', 'different', 'scenes', 'offering', 'further', 'insight', 'into', 'all', 'of', 'the', 'strangeness', 'going', 'down', 'in', 'the', 'movie', '?', 'apparently', ',', 'the', 'studio', 'took', 'this', 'film', 'away', 'from', 'its', 'director', 'and', 'chopped', 'it', 'up', 'themselves', ',', 'and', 'it', 'shows', '.', 'there', 'might', \"'\", 've', 'been', 'a', 'pretty', 'decent', 'teen', 'mind', '-', 'fuck', 'movie', 'in', 'here', 'somewhere', ',', 'but', 'i', 'guess', '\"', 'the', 'suits', '\"', 'decided', 'that', 'turning', 'it', 'into', 'a', 'music', 'video', 'with', 'little', 'edge', ',', 'would', 'make', 'more', 'sense', '.', 'the', 'actors', 'are', 'pretty', 'good', 'for', 'the', 'most', 'part', ',', 'although', 'wes', 'bentley', 'just', 'seemed', 'to', 'be', 'playing', 'the', 'exact', 'same', 'character', 'that', 'he', 'did', 'in', 'american', 'beauty', ',', 'only', 'in', 'a', 'new', 'neighborhood', '.', 'but', 'my', 'biggest', 'kudos', 'go', 'out', 'to', 'sagemiller', ',', 'who', 'holds', 'her', 'own', 'throughout', 'the', 'entire', 'film', ',', 'and', 'actually', 'has', 'you', 'feeling', 'her', 'character', \"'\", 's', 'unraveling', '.', 'overall', ',', 'the', 'film', 'doesn', \"'\", 't', 'stick', 'because', 'it', 'doesn', \"'\", 't', 'entertain', ',', 'it', \"'\", 's', 'confusing', ',', 'it', 'rarely', 'excites', 'and', 'it', 'feels', 'pretty', 'redundant', 'for', 'most', 'of', 'its', 'runtime', ',', 'despite', 'a', 'pretty', 'cool', 'ending', 'and', 'explanation', 'to', 'all', 'of', 'the', 'craziness', 'that', 'came', 'before', 'it', '.', 'oh', ',', 'and', 'by', 'the', 'way', ',', 'this', 'is', 'not', 'a', 'horror', 'or', 'teen', 'slasher', 'flick', '.', '.', '.', 'it', \"'\", 's', 'just', 'packaged', 'to', 'look', 'that', 'way', 'because', 'someone', 'is', 'apparently', 'assuming', 'that', 'the', 'genre', 'is', 'still', 'hot', 'with', 'the', 'kids', '.', 'it', 'also', 'wrapped', 'production', 'two', 'years', 'ago', 'and', 'has', 'been', 'sitting', 'on', 'the', 'shelves', 'ever', 'since', '.', 'whatever', '.', '.', '.', 'skip', 'it', '!', 'where', \"'\", 's', 'joblo', 'coming', 'from', '?', 'a', 'nightmare', 'of', 'elm', 'street', '3', '(', '7', '/', '10', ')', '-', 'blair', 'witch', '2', '(', '7', '/', '10', ')', '-', 'the', 'crow', '(', '9', '/', '10', ')', '-', 'the', 'crow', ':', 'salvation', '(', '4', '/', '10', ')', '-', 'lost', 'highway', '(', '10', '/', '10', ')', '-', 'memento', '(', '10', '/', '10', ')', '-', 'the', 'others', '(', '9', '/', '10', ')', '-', 'stir', 'of', 'echoes', '(', '8', '/', '10', ')'], 'neg')\n"
     ]
    }
   ],
   "source": [
    "print(new_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notice that unlike the data in Part 1, the text comes as a list of words instead of a single string. TextBlob is smart about this; it will treat both forms of data as expected.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now update our classifier with the new training data using the `update(new_data)` method, as well as test it using the larger test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9714285714285714\n",
      "Most Informative Features\n",
      "          contains(this) = False             pos : neg    =     31.8 : 1.0\n",
      "            contains(of) = False             pos : neg    =     21.6 : 1.0\n",
      "            contains(is) = False             pos : neg    =     17.7 : 1.0\n",
      "       contains(awesome) = True              pos : neg    =     17.7 : 1.0\n",
      "      contains(sandwich) = True              pos : neg    =     17.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.update(new_train)\n",
    "accuracy = cl.accuracy(test + new_test)\n",
    "\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = cl.accuracy(test + new_test)\n",
    "print(\"Accuracy: {0}\".format(accuracy))\n",
    "\n",
    "# Show 5 most informative features\n",
    "cl.show_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `classify()` method to classify a sentence with the updated and trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.classify(\"I can't believe I'm doing this.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Language Detector (Custom Feature Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important aspect that I haven't yet mentioned is `how features are being extracted from the text`.\n",
    "\n",
    "\n",
    "For a given document and training set train, TextBlob's default behavior is to compute which words in train are present in document. For example, the sentence \"It's just a flesh wound.\" might have features contains(flesh): True, contains(wound): True, and contains(knight): False.\n",
    "\n",
    "\n",
    "Of course, this simple feature extractor may not be appropriate for all problems. Here we'll create a `custom feature extractor for a language detector`.\n",
    "\n",
    "\n",
    "Here's the training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\n",
    "    (\"amor\", \"spanish\"),\n",
    "    (\"perro\", \"spanish\"),\n",
    "    (\"playa\", \"spanish\"),\n",
    "    (\"sal\", \"spanish\"),\n",
    "    (\"oceano\", \"spanish\"),\n",
    "    (\"love\", \"english\"),\n",
    "    (\"dog\", \"english\"),\n",
    "    (\"beach\", \"english\"),\n",
    "    (\"salt\", \"english\"),\n",
    "    (\"ocean\", \"english\")\n",
    "]\n",
    "test = [\n",
    "    (\"ropa\", \"spanish\"),\n",
    "    (\"comprar\", \"spanish\"),\n",
    "    (\"camisa\", \"spanish\"),\n",
    "    (\"agua\", \"spanish\"),\n",
    "    (\"telefono\", \"spanish\"),\n",
    "    (\"clothes\", \"english\"),\n",
    "    (\"buy\", \"english\"),\n",
    "    (\"shirt\", \"english\"),\n",
    "    (\"water\", \"english\"),\n",
    "    (\"telephone\", \"english\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feature extractor is simply a function that takes an argument text (the text to extract features from) and returns a dictionary of features.\n",
    "\n",
    "Let's create a very simple extractor that uses the last letter of a given word as its only feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last_letter(n)': True}\n"
     ]
    }
   ],
   "source": [
    "def extractor(word):\n",
    "    '''Extract the last letter of a word as the only feature.'''\n",
    "    feats = {}\n",
    "    last_letter = word[-1]\n",
    "    feats[\"last_letter({0})\".format(last_letter)] = True\n",
    "    return feats\n",
    "\n",
    "print(extractor(\"python\"))  # {'last_letter(n)': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass this feature extractor as the second argument to the constructor of a `NaiveBayesClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_detector = NaiveBayesClassifier(train, feature_extractor=extractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, compute accuracy and `informative features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          last_letter(o) = None           englis : spanis =      1.6 : 1.0\n",
      "          last_letter(a) = None           englis : spanis =      1.2 : 1.0\n",
      "          last_letter(e) = None           spanis : englis =      1.2 : 1.0\n",
      "          last_letter(g) = None           spanis : englis =      1.2 : 1.0\n",
      "          last_letter(h) = None           spanis : englis =      1.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "lang_detector.accuracy(test)  # 0.7\n",
    "lang_detector.show_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Not surprisingly, words that do not end with the letter \"o\" tend to be English.*"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a477e406acbd2e5d181cdd122dfb51ff73acdf0b608e3a81bbfb62ac2a7a365"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
